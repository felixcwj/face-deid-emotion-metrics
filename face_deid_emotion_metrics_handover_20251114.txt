Project: face-deid-emotion-metrics — compute identity, style, and emotion similarity for mirrored `input/` vs `output/` datasets.
Repo: C:\projects\face-deid-emotion-metrics
Dataset: Base directory D:\RAPA (mirrored `input/` and `output/`, `.jpg` stills and `.mp4` videos share the same relative paths).

## Quick usage (PowerShell 7)
- 무작위 5개 샘플:
  ```powershell
  Set-Location C:\projects\face-deid-emotion-metrics
  .\.venv\Scripts\python.exe -m face_deid_emotion_metrics.cli --base-dir D:\RAPA --random-sample 5 --random-output D:\RAPA\10_test5.xlsx
  ```
- Top/Bottom 40 (디터미니스틱):
  ```powershell
  Set-Location C:\projects\face-deid-emotion-metrics
  .\.venv\Scripts\python.exe -m face_deid_emotion_metrics.cli --base-dir D:\RAPA --top-bottom-40-only --random-output D:\RAPA\rapa_report_top_bottom_40.xlsx
  ```
  (또는 PowerShell profile에 등록된 `rapa 40` 사용)

Pipeline summary:
- Every `.jpg` and `.mp4` under `input/` must have a twin under `output/` with the same relative path; each pair becomes its own Excel row.
- Metrics per row (in order): filename, FaceNet (%), LPIPS (%), Final score (%), Emoti emotion (%), Person count, Duration. (Emoti replaces the legacy FER/DeepFace columns and uses EmotiEffLib’s PyTorch backend.)
- FaceNet/LPIPS/Final/MTCNN detection/Emoti all run on the CUDA device (`cuda:0`). Person count = number of distinct tracked faces in that file; Duration is populated for `.mp4` rows (e.g., `47s`, `2m 05s`).
- Excel formatting: centered cells, one-decimal metrics, bold Final score column, thick borders around header/table and LPIPS|Final|Emoti separators.

Code structure:
- src/face_deid_emotion_metrics/: cli.py, pipeline.py, models_face.py, models_emotion.py, excel_writer.py, config.py.
- scripts/run_rapa.ps1 — Windows helper for quick samples/debugging.
- scripts/deid.ps1 — interactive PowerShell launcher (`deid`).
- scripts/install_deid_alias.ps1 — one-time profile updater so every new PowerShell session knows about `deid`.
- `--max-files N` is a debug-only limiter; omit it for full counts.

Environment setup (Windows PowerShell, GPU required):
```powershell
Set-Location C:\projects\face-deid-emotion-metrics
python -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt  # pulls emotiefflib + timm<0.10 for compatibility
pip install -e .
```

Interactive PowerShell helper (`deid`):
```powershell
Set-Location C:\projects\face-deid-emotion-metrics
pwsh -File .\scripts\install_deid_alias.ps1  # run once to register the function
```
Open a new PowerShell window (or reload your profile) and use:
```powershell
deid
```
The script asks for the dataset folder (e.g., `D:\RAPA`), an output Excel path (default `<base>\rapa_report_interactive.xlsx`), and a final confirmation (`Y`). Typing `Y` launches the CLI; anything else cancels.

Direct CLI usage (same behavior as `deid` but without prompts):
```powershell
python -m face_deid_emotion_metrics.cli --base-dir D:\RAPA --output D:\RAPA\rapa_report.xlsx
```

GPU checks (optional, from the venv):
```powershell
python - <<'PY'
import torch
print(torch.__version__)
print('CUDA available:', torch.cuda.is_available())
if torch.cuda.is_available():
    print('Device 0:', torch.cuda.get_device_name(0))
PY
```

Notes:
- MTCNN face detection now runs on the same CUDA device as FaceNet/LPIPS/emotions, so a missing GPU immediately aborts via `require_cuda_device()`.
- EmotiEffLib relies on EfficientNet weights from timm 0.9.x. Keep the `timm>=0.9,<0.10` constraint (already in requirements.txt) to avoid the `conv_s2d` attribute error seen in timm 1.x.
- Large runs still benefit from fast disks/CPUs because video decoding and data loading happen on the host, but all neural nets remain on GPU.

[2025-11-17] Optimized emotion batching in pipeline (single EmotiEffLib call for original+output faces) and enabled torch.backends.cudnn.benchmark for faster CUDA kernels; metrics remain unchanged.
[2025-11-17] Accelerated video path: sequential frame sampling (no random seeks) + batched MTCNN detection per chunk; GPU work unchanged but throughput improved.
[2025-11-17] Decord now requires CUDA build; pipeline aborts if GPU decode missing (build from source per README).
[2025-11-17] Added scripts/install_decord_gpu.ps1 to auto-build CUDA decord (installs Build Tools/FFmpeg, verifies NVDEC).
[2025-11-17] install_decord_gpu.ps1 now enforces admin rights, installs CUDA Toolkit 12.6 via winget or NVIDIA's network installer, then builds GPU-only decord.
[2025-11-17] CUDA installer now defaults to C:\face_deid_decord (override with -InstallRoot) to avoid non-ASCII paths; specify -CudaToolkit for existing installs.
[2025-11-17] CMake 계속 'No CUDA toolset found' → 원인: CUDA 12.6 설치 시 Visual Studio Integration 빠짐. 해결: CUDA 12.6 삭제 후 Custom 설치에서 VS Integration 포함, 환경변수 수동 지정, 아래 명령으로 빌드:
  - 관리자 PowerShell 예시:
    ```
    $env:CUDA_PATH = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6"
    $env:CUDA_PATH_V12_6 = $env:CUDA_PATH
    $env:CUDACXX = Join-Path $env:CUDA_PATH "bin\nvcc.exe"
    $env:PATH = "$env:CUDA_PATH\bin;$env:PATH"
    & "C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\Common7\Tools\VsDevCmd.bat" -arch=x64
    cmake -S C:\face_deid_decord\decord -B C:\face_deid_decord\decord\build `
          -G "Visual Studio 17 2022" -A x64 `
          -DUSE_CUDA=ON -DCMAKE_BUILD_TYPE=Release `
          "-DFFMPEG_DIR=C:\face_deid_decord\ffmpeg\ffmpeg-master-latest-win64-lgpl" `
          "-DCUDAToolkit_ROOT=$env:CUDA_PATH" `
          "-DCMAKE_CUDA_COMPILER=$env:CUDACXX"
    cmake --build C:\face_deid_decord\decord\build --config Release
    ```
  - 수동 설치가 귀찮으면 새 챗 세션에서 위 과정을 묻도록 프롬프트(복사용) 준비해 두었음.
[2025-11-17] WSL 자동화/ffmpeg GPU 파이프라인 + 진행률 개선
- WSL2에서 ffmpeg CUDA hwaccel을 기본 비디오 백엔드로 사용하게 구성 (scripts/wsl/*, scripts/run_rapa_wsl.ps1). Windows에서는 `rapa` 명령 한 줄로 전체 보고서 생성 가능.
- `video_reader.py`에 ffmpeg/Decord 백엔드 추상화 추가, CLI `--video-backend` 옵션 유지. Decord는 선택 사항으로 전환.
- Face pipeline(`models_face.py`, `pipeline.py`)이 세분화된 진행률 이벤트를 발생시키고 CLI에서 전체/파일별 tqdm 바를 표시해 0.01% 단위 전체 진행률과 파일별 단계별 상태(로딩→디코드→프레임 처리→감정/집계)를 동시에 확인 가능.
- `docs/wsl.md`와 README에 새로운 실행 방식과 GPU 디코딩 방법 문서화. `.venv_wsl`은 git에서 제외.
- 검증: `rapa -MaxFiles 2` 및 `rapa -MaxFiles 1` 로 GPU 디코딩 + 전체 파이프라인 동작 확인, 산출물 `D:\RAPA\rapa_report_full_wsl.xlsx`.

WSL 실행 요약:
1) `wsl.exe -- bash -lc "./scripts/wsl/setup_env.sh"`
2) PowerShell 7 관리자 창에서 `rapa` (또는 `pwsh -File .\scripts\run_rapa_wsl.ps1 -BaseDir D:\RAPA -Output D:\RAPA\rapa_report_full_wsl.xlsx`).
3) 필요 시 `wsl.exe -- bash -lc "source /mnt/c/projects/face-deid-emotion-metrics/.venv_wsl/bin/activate && python scripts/wsl/verify_gpu_decode.py --video /mnt/d/RAPA/input/<sample>.mp4 --backend ffmpeg"` 로 NVDEC 확인.
[2025-11-18] Profiling mode + Final score refresh

### CLI additions
- `--profile-only`: runs the full GPU pipeline on 10 deterministically sampled input/output pairs without touching Excel. Same device/model loading as the report run so timings are representative.
- `--seed`: overrides the profiling sampler seed (default 42) so you can re-run a specific 10-file set.
- `--resize-512`: forces every decoded frame/image to 512x512 before detection/inference. Useful for profiling resize cost; leave unset for original resolution.

### Profiling workflow
- Windows: `python -m face_deid_emotion_metrics.cli --base-dir D:\RAPA --profile-only`
- WSL: `python -m face_deid_emotion_metrics.cli --base-dir /mnt/d/RAPA --profile-only`
- Output includes `load/resize/facenet/lpips/emoti/other/total` lines in milliseconds + percent of the total runtime. Excel writes are skipped so you can collect numbers quickly.

### PowerShell helper (`rapa`)
```powershell
function rapa {
    param(
        [string]$BaseDir = "D:\RAPA",
        [string]$Output = ""
    )
    Set-Location "C:\projects\face-deid-emotion-metrics"
    $python = "C:\projects\face-deid-emotion-metrics\.venv\Scripts\python.exe"
    if (-not $Output) {
        $Output = Join-Path $BaseDir "rapa_report_samples.xlsx"
    }
    & $python -m face_deid_emotion_metrics.cli --base-dir $BaseDir --output $Output @Args
}
```
Paste into your PowerShell 7 profile to run the full Excel pipeline with `rapa`; pass extra switches (e.g., `--resize-512`) via additional arguments.

### Final score weighting
- `src/face_deid_emotion_metrics/config.py` exposes `FINAL_SCORE_FACENET_WEIGHT`, `FINAL_SCORE_LPIPS_WEIGHT`, `FINAL_SCORE_SCALE`, `FINAL_SCORE_BIAS` (0.2 / 0.8 / 0.6154 / 0.6154).
- Formula follows the 3단계 구조: normalize FaceNet/LPIPS → `w = 0.2 * f + 0.8 * l` → `S = 100 * (FINAL_SCORE_SCALE * w**2 + FINAL_SCORE_BIAS)` → `Final = clamp_0_40(S - 60)`. 이렇게 하면 0~40 위험도 범위로 압축하면서 높은 유사도만 더 크게 드러납니다.
[2025-11-18] Media-specific profiling + debug sampling
- New CLI flag `--profile-kind {all|image|video}` lets profiling runs target only stills, only videos, or the combined pool. Use `--video-backend ffmpeg` on Windows boxes without GPU decoders.
- `--debug-random-10` generates 5 random image pairs + 5 random video pairs (seeded via `--seed`) and writes filename/media type/FaceNet/LPIPS/Final score to `random_debug_10.xlsx`.
- Metric outputs are clamped to [0.1, 99.9] and rows with no detected faces remain blank instead of reporting 0/0/0.

[2025-11-18] Sample workbook refresh
- Default report runs now build `rapa_report_samples.xlsx` with three sheets:
  - `sample_40`: first 20 + last 20 sorted paths (deduplicated if the set is smaller than 40).
  - `sample_100`: 100 random paths chosen with the CLI `--seed`.
  - `sample_500`: 500 random paths (or every file if the dataset is smaller).
  Each row now writes `Filename`, `Facenet`, `LPIPS`, `Final Score`, `Emoti`, `Person Count`, `Duration`. Stage timings, media type, and error columns were removed so the workbook stays reviewer-facing while timing data lives in the logs/profiler output.
- Runs are resumable: if the workbook already contains rows for a sheet, those filenames are skipped. Appends happen one row at a time and the workbook is saved immediately, so killing `rapa` midway and rerunning simply fills in the missing paths.
- `<BaseDir>\\근거.txt` is no longer generated automatically—archive or edit the existing file manually when you need to distribute updated rationale text.
- PowerShell helper (drop in your PS7 profile) now defaults to `rapa_report_samples.xlsx` and accepts overrides:
```powershell
function rapa {
    param(
        [string]$BaseDir = "D:\RAPA",
        [string]$Output = ""
    )
    if (-not $Output) { $Output = Join-Path $BaseDir "rapa_report_samples.xlsx" }
    Set-Location "C:\projects\face-deid-emotion-metrics"
    $python = "C:\projects\face-deid-emotion-metrics\.venv\Scripts\python.exe"
    & $python -m face_deid_emotion_metrics.cli --base-dir $BaseDir --output $Output --video-backend ffmpeg @Args
}
```
- Typical usage: `rapa` (defaults to `D:\RAPA`), or `rapa -BaseDir "D:\RAPA" -Output "D:\RAPA\custom.xlsx" --video-backend ffmpeg`. The helper always produces the three-sheet workbook plus `<BaseDir>\근거.txt`.
- Running `rapa 40` in PowerShell 7 is now a shortcut for the deterministic first/last 20 flow: it assumes `D:\RAPA`, writes `<BaseDir>\rapa_report_top_bottom_40.xlsx`, and passes `--top-bottom-40-only` to the CLI so only 40 rows are produced.

[2025-11-18] Excel layout + robustness refresh
- Columns A–G are `Filename`, `Facenet`, `LPIPS`, `Final Score`, `Emoti`, `Person Count`, `Duration`. All cells are center-aligned; Facenet/LPIPS/Final/Emoti display one decimal; Person Count is integer; Duration shows strings such as `42s` (images stay blank).
- Column widths auto-fit per sheet so long RAPA filenames are readable without manual resizing.
- The Final Score column is bold (header + values) and highlighted with thick vertical borders on both sides. The header row has a thick bottom border, the table perimeter (A–G) uses a thick frame, and the interiors between LPIPS|Final and Final|Emoti also get thick separators per row.
- Pipeline resiliency:
  - Emotion batching no longer triggers the boolean-mask mismatch; rows with invalid probabilities fall back to uniform vectors.
  - Every per-file execution now records stage timings (`load_ms`, `resize_ms`, etc.) and wraps processing in a try/except so bad files still yield a row with the `Error` field populated instead of crashing the run.
  - `_process_single_pair` surfaces stage progress in the logs (e.g., "Processing foo.mp4: processing frames 21/32").
  - All float conversions guard against `None` (e.g., debug sample generation), so there are no `float(NoneType)` crashes.
- Media coverage:
  - `PipelineConfig.file_extensions` now includes `.png`, and the sorted sample lists (`sample_40/100/500`) consider both stills and videos. Media Type now clearly shows `"image"` or `"video"` in every sheet, and Person Count/Duration respect those semantics (images leave Duration blank; videos show seconds only).
  - Video decoding defaults to `--video-backend auto`, which tries the CUDA Decord backend first and transparently falls back to ffmpeg if GPU decode isn’t available. The bundled `rapa` helper forces `--video-backend ffmpeg` on Windows for maximum compatibility; WSL runs can simply rely on auto.


[2025-11-19] Final score polish
- Final score는 `f=FaceNet/100`, `l=LPIPS/100`, `w=0.2*f+0.8*l`, `S=100*(0.6154*w^2+0.6154)`, `Final=clamp_0_40(S-60)` 순서로 계산되어 항상 0~40 범위에 머물며, RAPA PPT의 “중간 구간 억제/높은 구간 증폭” 요구를 그대로 따릅니다.
- Workbook presentation is locked to columns A–G = Filename, Facenet, LPIPS, Final Score, Emoti, Person Count, Duration. Column E (Final Score) is bold and boxed in by thick borders, headers have a thick separator, LPIPS|Final and Final|Emoti boundaries are thick, and A–G are wrapped by a thick outer frame. Widths auto-fit per sheet so long Korean filenames render without manual resizing.
- `<BaseDir>\\근거.txt` is no longer generated automatically; archive the existing file manually if historical rationale text is still required.
- Pipeline resiliency highlights: emotion batching now normalizes any malformed probability tensors before division (no more boolean-mask mismatches), `_clip_box` skips invalid/NaN bounding boxes instead of calling `float(None)`, and `_process_single_pair` logs stage progress while capturing profiler timings so failures still emit a row with the `Error` field populated.
- `rapa` (PowerShell helper in scripts/run_rapa.ps1 or pasted into your PS7 profile) still defaults to `D:\RAPA`, forces `--video-backend ffmpeg`, resumes partial workbooks, and now guarantees that image + video extensions are both enumerated (`.jpg/.jpeg/.png/.mp4/.mov/.mkv`). Typical one-liner: `rapa` or `rapa -BaseDir 'D:\RAPA' -Output 'D:\RAPA\rapa_report_samples.xlsx' --resize-512`.

